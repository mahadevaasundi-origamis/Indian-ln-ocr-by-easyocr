{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCaDm5eKuzEevxceo2SYte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahadevaasundi-origamis/Indian-ln-ocr-by-easyocr/blob/main/WebLister.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install playwright beautifulsoup4 requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVeso_Mq3XhQ",
        "outputId": "24046000-418d-4534-9a95-2985dde0548b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting playwright\n",
            "  Downloading playwright-1.54.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting pyee<14,>=13 (from playwright)\n",
            "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Downloading playwright-1.54.0-py3-none-manylinux1_x86_64.whl (45.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.54.0 pyee-13.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44f4e92a",
        "outputId": "29cab815-bb3d-415a-96f5-f75e14f40e45"
      },
      "source": [
        "!playwright install"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Chromium 139.0.7258.5 (playwright build v1181)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1181/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G172.5 MiB [] 0% 131.3s\u001b[0K\u001b[1G172.5 MiB [] 0% 54.6s\u001b[0K\u001b[1G172.5 MiB [] 0% 29.8s\u001b[0K\u001b[1G172.5 MiB [] 0% 16.3s\u001b[0K\u001b[1G172.5 MiB [] 0% 8.0s\u001b[0K\u001b[1G172.5 MiB [] 1% 5.1s\u001b[0K\u001b[1G172.5 MiB [] 2% 4.1s\u001b[0K\u001b[1G172.5 MiB [] 3% 3.4s\u001b[0K\u001b[1G172.5 MiB [] 4% 3.0s\u001b[0K\u001b[1G172.5 MiB [] 5% 2.7s\u001b[0K\u001b[1G172.5 MiB [] 5% 3.0s\u001b[0K\u001b[1G172.5 MiB [] 6% 2.9s\u001b[0K\u001b[1G172.5 MiB [] 6% 2.8s\u001b[0K\u001b[1G172.5 MiB [] 7% 2.6s\u001b[0K\u001b[1G172.5 MiB [] 8% 2.4s\u001b[0K\u001b[1G172.5 MiB [] 9% 2.4s\u001b[0K\u001b[1G172.5 MiB [] 11% 2.2s\u001b[0K\u001b[1G172.5 MiB [] 12% 2.1s\u001b[0K\u001b[1G172.5 MiB [] 14% 2.0s\u001b[0K\u001b[1G172.5 MiB [] 15% 2.0s\u001b[0K\u001b[1G172.5 MiB [] 16% 1.8s\u001b[0K\u001b[1G172.5 MiB [] 17% 1.8s\u001b[0K\u001b[1G172.5 MiB [] 19% 1.7s\u001b[0K\u001b[1G172.5 MiB [] 20% 1.6s\u001b[0K\u001b[1G172.5 MiB [] 21% 1.6s\u001b[0K\u001b[1G172.5 MiB [] 22% 1.5s\u001b[0K\u001b[1G172.5 MiB [] 23% 1.5s\u001b[0K\u001b[1G172.5 MiB [] 25% 1.4s\u001b[0K\u001b[1G172.5 MiB [] 26% 1.4s\u001b[0K\u001b[1G172.5 MiB [] 26% 1.5s\u001b[0K\u001b[1G172.5 MiB [] 27% 1.5s\u001b[0K\u001b[1G172.5 MiB [] 29% 1.4s\u001b[0K\u001b[1G172.5 MiB [] 30% 1.3s\u001b[0K\u001b[1G172.5 MiB [] 31% 1.3s\u001b[0K\u001b[1G172.5 MiB [] 32% 1.3s\u001b[0K\u001b[1G172.5 MiB [] 34% 1.2s\u001b[0K\u001b[1G172.5 MiB [] 35% 1.2s\u001b[0K\u001b[1G172.5 MiB [] 37% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 38% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 39% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 41% 1.0s\u001b[0K\u001b[1G172.5 MiB [] 42% 1.0s\u001b[0K\u001b[1G172.5 MiB [] 43% 1.0s\u001b[0K\u001b[1G172.5 MiB [] 45% 0.9s\u001b[0K\u001b[1G172.5 MiB [] 46% 0.9s\u001b[0K\u001b[1G172.5 MiB [] 48% 0.9s\u001b[0K\u001b[1G172.5 MiB [] 49% 0.8s\u001b[0K\u001b[1G172.5 MiB [] 51% 0.8s\u001b[0K\u001b[1G172.5 MiB [] 52% 0.8s\u001b[0K\u001b[1G172.5 MiB [] 54% 0.7s\u001b[0K\u001b[1G172.5 MiB [] 55% 0.7s\u001b[0K\u001b[1G172.5 MiB [] 56% 0.7s\u001b[0K\u001b[1G172.5 MiB [] 58% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 59% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 61% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 62% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 64% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 65% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 66% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 67% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 68% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 69% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 70% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 71% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 72% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 73% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 74% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 75% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 76% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 78% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 79% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 80% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 82% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 83% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 84% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 86% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 87% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 88% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 89% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 90% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 91% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 92% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 93% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 94% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 95% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 96% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 97% 0.0s\u001b[0K\u001b[1G172.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G172.5 MiB [] 99% 0.0s\u001b[0K\u001b[1G172.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 139.0.7258.5 (playwright build v1181) downloaded to /root/.cache/ms-playwright/chromium-1181\n",
            "Downloading Chromium Headless Shell 139.0.7258.5 (playwright build v1181)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1181/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G104.8 MiB [] 0% 0.0s\u001b[0K\u001b[1G104.8 MiB [] 0% 26.7s\u001b[0K\u001b[1G104.8 MiB [] 0% 12.3s\u001b[0K\u001b[1G104.8 MiB [] 0% 8.3s\u001b[0K\u001b[1G104.8 MiB [] 1% 5.1s\u001b[0K\u001b[1G104.8 MiB [] 2% 4.1s\u001b[0K\u001b[1G104.8 MiB [] 3% 3.3s\u001b[0K\u001b[1G104.8 MiB [] 3% 3.1s\u001b[0K\u001b[1G104.8 MiB [] 4% 2.6s\u001b[0K\u001b[1G104.8 MiB [] 5% 2.8s\u001b[0K\u001b[1G104.8 MiB [] 6% 2.5s\u001b[0K\u001b[1G104.8 MiB [] 7% 2.4s\u001b[0K\u001b[1G104.8 MiB [] 8% 2.3s\u001b[0K\u001b[1G104.8 MiB [] 8% 2.2s\u001b[0K\u001b[1G104.8 MiB [] 9% 2.5s\u001b[0K\u001b[1G104.8 MiB [] 10% 2.5s\u001b[0K\u001b[1G104.8 MiB [] 11% 2.5s\u001b[0K\u001b[1G104.8 MiB [] 12% 2.4s\u001b[0K\u001b[1G104.8 MiB [] 13% 2.2s\u001b[0K\u001b[1G104.8 MiB [] 14% 2.2s\u001b[0K\u001b[1G104.8 MiB [] 15% 2.1s\u001b[0K\u001b[1G104.8 MiB [] 16% 2.1s\u001b[0K\u001b[1G104.8 MiB [] 17% 1.9s\u001b[0K\u001b[1G104.8 MiB [] 19% 1.8s\u001b[0K\u001b[1G104.8 MiB [] 20% 1.8s\u001b[0K\u001b[1G104.8 MiB [] 21% 1.7s\u001b[0K\u001b[1G104.8 MiB [] 22% 1.7s\u001b[0K\u001b[1G104.8 MiB [] 23% 1.6s\u001b[0K\u001b[1G104.8 MiB [] 24% 1.6s\u001b[0K\u001b[1G104.8 MiB [] 25% 1.6s\u001b[0K\u001b[1G104.8 MiB [] 26% 1.6s\u001b[0K\u001b[1G104.8 MiB [] 27% 1.5s\u001b[0K\u001b[1G104.8 MiB [] 29% 1.4s\u001b[0K\u001b[1G104.8 MiB [] 30% 1.4s\u001b[0K\u001b[1G104.8 MiB [] 31% 1.3s\u001b[0K\u001b[1G104.8 MiB [] 32% 1.3s\u001b[0K\u001b[1G104.8 MiB [] 33% 1.3s\u001b[0K\u001b[1G104.8 MiB [] 34% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 35% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 36% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 37% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 38% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 39% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 40% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 42% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 43% 1.0s\u001b[0K\u001b[1G104.8 MiB [] 43% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 44% 1.0s\u001b[0K\u001b[1G104.8 MiB [] 46% 1.0s\u001b[0K\u001b[1G104.8 MiB [] 49% 0.9s\u001b[0K\u001b[1G104.8 MiB [] 51% 0.8s\u001b[0K\u001b[1G104.8 MiB [] 54% 0.8s\u001b[0K\u001b[1G104.8 MiB [] 55% 0.7s\u001b[0K\u001b[1G104.8 MiB [] 58% 0.7s\u001b[0K\u001b[1G104.8 MiB [] 60% 0.6s\u001b[0K\u001b[1G104.8 MiB [] 63% 0.6s\u001b[0K\u001b[1G104.8 MiB [] 66% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 68% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 69% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 71% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 73% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 76% 0.3s\u001b[0K\u001b[1G104.8 MiB [] 78% 0.3s\u001b[0K\u001b[1G104.8 MiB [] 81% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 84% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 86% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 89% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 92% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 94% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 97% 0.0s\u001b[0K\u001b[1G104.8 MiB [] 99% 0.0s\u001b[0K\u001b[1G104.8 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 139.0.7258.5 (playwright build v1181) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1181\n",
            "Downloading Firefox 140.0.2 (playwright build v1489)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1489/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G92.5 MiB [] 0% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 0% 6.8s\u001b[0K\u001b[1G92.5 MiB [] 0% 5.7s\u001b[0K\u001b[1G92.5 MiB [] 1% 3.3s\u001b[0K\u001b[1G92.5 MiB [] 2% 2.1s\u001b[0K\u001b[1G92.5 MiB [] 3% 2.0s\u001b[0K\u001b[1G92.5 MiB [] 5% 1.6s\u001b[0K\u001b[1G92.5 MiB [] 7% 1.4s\u001b[0K\u001b[1G92.5 MiB [] 9% 1.2s\u001b[0K\u001b[1G92.5 MiB [] 10% 1.3s\u001b[0K\u001b[1G92.5 MiB [] 11% 1.3s\u001b[0K\u001b[1G92.5 MiB [] 11% 1.4s\u001b[0K\u001b[1G92.5 MiB [] 13% 1.3s\u001b[0K\u001b[1G92.5 MiB [] 15% 1.2s\u001b[0K\u001b[1G92.5 MiB [] 17% 1.1s\u001b[0K\u001b[1G92.5 MiB [] 18% 1.1s\u001b[0K\u001b[1G92.5 MiB [] 20% 1.0s\u001b[0K\u001b[1G92.5 MiB [] 22% 1.0s\u001b[0K\u001b[1G92.5 MiB [] 23% 1.0s\u001b[0K\u001b[1G92.5 MiB [] 25% 0.9s\u001b[0K\u001b[1G92.5 MiB [] 27% 0.9s\u001b[0K\u001b[1G92.5 MiB [] 29% 0.8s\u001b[0K\u001b[1G92.5 MiB [] 32% 0.8s\u001b[0K\u001b[1G92.5 MiB [] 35% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 36% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 38% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 41% 0.6s\u001b[0K\u001b[1G92.5 MiB [] 43% 0.6s\u001b[0K\u001b[1G92.5 MiB [] 46% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 48% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 49% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 52% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 55% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 58% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 61% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 64% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 67% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 70% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 72% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 75% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 78% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 81% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 84% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 87% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 89% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 91% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 92% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 93% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 94% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 96% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 140.0.2 (playwright build v1489) downloaded to /root/.cache/ms-playwright/firefox-1489\n",
            "Downloading Webkit 26.0 (playwright build v2191)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2191/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G94.4 MiB [] 0% 71.8s\u001b[0K\u001b[1G94.4 MiB [] 0% 26.6s\u001b[0K\u001b[1G94.4 MiB [] 0% 13.3s\u001b[0K\u001b[1G94.4 MiB [] 0% 8.2s\u001b[0K\u001b[1G94.4 MiB [] 1% 4.3s\u001b[0K\u001b[1G94.4 MiB [] 2% 3.1s\u001b[0K\u001b[1G94.4 MiB [] 3% 2.7s\u001b[0K\u001b[1G94.4 MiB [] 4% 2.2s\u001b[0K\u001b[1G94.4 MiB [] 6% 1.9s\u001b[0K\u001b[1G94.4 MiB [] 7% 1.7s\u001b[0K\u001b[1G94.4 MiB [] 8% 1.6s\u001b[0K\u001b[1G94.4 MiB [] 10% 1.7s\u001b[0K\u001b[1G94.4 MiB [] 11% 1.8s\u001b[0K\u001b[1G94.4 MiB [] 12% 1.7s\u001b[0K\u001b[1G94.4 MiB [] 14% 1.6s\u001b[0K\u001b[1G94.4 MiB [] 15% 1.5s\u001b[0K\u001b[1G94.4 MiB [] 16% 1.5s\u001b[0K\u001b[1G94.4 MiB [] 17% 1.5s\u001b[0K\u001b[1G94.4 MiB [] 18% 1.5s\u001b[0K\u001b[1G94.4 MiB [] 20% 1.4s\u001b[0K\u001b[1G94.4 MiB [] 22% 1.3s\u001b[0K\u001b[1G94.4 MiB [] 23% 1.3s\u001b[0K\u001b[1G94.4 MiB [] 25% 1.2s\u001b[0K\u001b[1G94.4 MiB [] 26% 1.2s\u001b[0K\u001b[1G94.4 MiB [] 28% 1.1s\u001b[0K\u001b[1G94.4 MiB [] 30% 1.1s\u001b[0K\u001b[1G94.4 MiB [] 32% 1.0s\u001b[0K\u001b[1G94.4 MiB [] 34% 1.0s\u001b[0K\u001b[1G94.4 MiB [] 36% 0.9s\u001b[0K\u001b[1G94.4 MiB [] 37% 0.9s\u001b[0K\u001b[1G94.4 MiB [] 38% 0.9s\u001b[0K\u001b[1G94.4 MiB [] 40% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 41% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 43% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 44% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 46% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 48% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 49% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 51% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 53% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 55% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 57% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 59% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 61% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 63% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 66% 0.4s\u001b[0K\u001b[1G94.4 MiB [] 68% 0.4s\u001b[0K\u001b[1G94.4 MiB [] 70% 0.4s\u001b[0K\u001b[1G94.4 MiB [] 72% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 74% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 76% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 77% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 78% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 79% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 80% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 83% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 85% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 86% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 89% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 91% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 92% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 94% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 96% 0.0s\u001b[0K\u001b[1G94.4 MiB [] 98% 0.0s\u001b[0K\u001b[1G94.4 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 26.0 (playwright build v2191) downloaded to /root/.cache/ms-playwright/webkit-2191\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 2% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 11% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 27% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 70% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libavif.so.13                                    ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:269:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:105:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:914:14)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:1036:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/server/registry/index.js:1025:7)\n",
            "    at async i.<anonymous> (/usr/local/lib/python3.11/dist-packages/playwright/driver/package/lib/cli/program.js:222:7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYMLyB5Q3J5I",
        "outputId": "0852e6b6-bb1d-4b23-d620-9795f779c868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected URLs:\n",
            "Economic Times - https://economictimes.indiatimes.com/industry/services/property-/-cstruction/indiqube-leases-3-2-lakh-sq-ft-in-bengaluru-targets-aum-of-11-47-mn-sq-ft-by-fy28/articleshow/122871092.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/markets/bonds/despite-rbis-rate-cuts-indian-g-sec-yields-remain-range-bound-due-to-us-yield-pressures-says-rajkumar-subramanian/articleshow/122876143.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/markets/bonds/three-indian-infra-investment-trusts-eye-500-million-debt-in-coming-weeks-sources-say/articleshow/122886742.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/markets/expert-view/see-a-long-runway-for-td-segment-in-power-sector-nischal-maheshwari/articleshow/122876443.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/mf/analysis/iex-mutual-funds-slash-stake-while-fpis-and-retail-investors-raise-exposure-in-june-quarter/articleshow/122877836.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/mf/mf-news/resurgent-india-launches-special-situation-aif-fund-targets-rs-500-crore/articleshow/122878316.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/tech/funding/infra-automation-startup-enlite-raises-rs-46-crore-in-a-funding-round-led-by-avaana-capital/articleshow/122864217.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/tech/funding/karnataka-tech-ecosystems-fundraising-plummets-to-1-7-billion-in-h1-2025-bengaluru-leads/articleshow/122878904.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/tech/funding/semiconductor-startup-netrasemi-raises-rs-107-crore-from-zoho-unicorn-india-ventures/articleshow/122880826.cms\n",
            "Economic Times - https://economictimes.indiatimes.com/tech/newsletters/morning-dispatch/paypal-ceo-interview-infosys-q1-report/articleshow/122869753.cms\n",
            "Entrackr - https://entrackr.com/exclusive/exclusive-shadowfax-to-raise-rs-2000-cr-via-ipo-fresh-issue-and-ofs-at-rs-1000-cr-each-9530994\n",
            "Entrackr - https://entrackr.com/news/bnpl-firm-simpl-under-ed-lens-for-rs-913-cr-fdi-violations-9530024\n",
            "Entrackr - https://entrackr.com/news/edtech-unicorn-physicswallah-receives-sebi-nod-for-ipo-9532638\n",
            "Entrackr - https://entrackr.com/news/kickcash-crosses-1-Mn-arr-in-india-eyes-rewarded-ua-space-in-developed-markets-9531431\n",
            "Entrackr - https://entrackr.com/news/superk-raises-rs-100-cr-led-by-binny-bansal-and-mithun-sacheti-9529906\n",
            "Entrackr - https://entrackr.com/snippets/enlite-raises-rs-46-cr-in-series-a-round-led-by-avaana-capital-9529908\n",
            "Entrackr - https://entrackr.com/snippets/eveez-raises-54-mn-in-series-a-led-by-michael-susan-dell-foundation-9531676\n",
            "Entrackr - https://entrackr.com/snippets/insurtech-startup-bharatsure-raises-rs-6-cr-led-by-ipv-9530132\n",
            "Entrackr - https://entrackr.com/snippets/mental-health-startup-lissun-acquires-us-based-being-cares-inc-9531025\n",
            "Entrackr - https://entrackr.com/snippets/semiconductor-startup-netrasemi-raises-rs-107-cr-led-by-zoho-corp-and-unicorn-india-ventures-9530646\n",
            "Inc 42 - https://inc42.com/buzz/\n",
            "Inc 42 - https://inc42.com/buzz/#content\n",
            "Inc 42 - https://inc42.com/buzz/google-vs-cci-big-tech-major-moves-sc-against-nclat-ruling/\n",
            "Inc 42 - https://inc42.com/buzz/very-hard-to-build-a-brand-on-quick-commerce-innovists-rohit-chawla/\n",
            "VCCircle - https://www.vccircle.com/ascertiscredit-making-a-quick-exit-from-india-portfolio-firm\n",
            "VCCircle - https://www.vccircle.com/binnybansal-mithun-sacheti-lead-superk-s-series-b-round\n",
            "VCCircle - https://www.vccircle.com/blackstones-q2-profit-tops-estimate-on-credit-strength-fee-gains\n",
            "VCCircle - https://www.vccircle.com/cppibto-exit-real-estate-platform-with-indian-developer-for-631-mn\n",
            "VCCircle - https://www.vccircle.com/deeptech-vc-yali-capital-closes-maiden-fund-exceeds-target\n",
            "VCCircle - https://www.vccircle.com/incredmoney-plans-new-fundraise-to-fuel-expansion\n",
            "VCCircle - https://www.vccircle.com/industry/consumer\n",
            "VCCircle - https://www.vccircle.com/industry/finance\n",
            "VCCircle - https://www.vccircle.com/industry/health-care\n",
            "VCCircle - https://www.vccircle.com/industry/infrastructure\n",
            "VCCircle - https://www.vccircle.com/industry/people\n",
            "VCCircle - https://www.vccircle.com/kraheja-corp-backed-mindspace-reit-marks-first-third-party-acquisition\n",
            "VCCircle - https://www.vccircle.com/natcoto-buy-226-mn-stake-in-south-african-drugmaker-adcock-ingram\n",
            "VCCircle - https://www.vccircle.com/netrasemienlite-others-snag-funding-lissun-acquires-us-mental-health-startup\n",
            "VCCircle - https://www.vccircle.com/nsdlsets-price-band-for-464-mn-ipo-nse-idbi-bank-to-cut-stake\n",
            "VCCircle - https://www.vccircle.com/oncevalued-at-over-200-mn-proptiger-goes-for-a-song\n",
            "VCCircle - https://www.vccircle.com/pefirms-local-energy-companies-vie-for-stake-in-gentari-s-india-business\n",
            "VCCircle - https://www.vccircle.com/rivendellpe-taking-sharp-haircut-on-another-legacy-india-investment\n",
            "VCCircle - https://www.vccircle.com/sebigreenlights-physicswallah-s-pre-ipo-draft-filing\n",
            "VCCircle - https://www.vccircle.com/sugar-cosmetics-backer-l-catterton-names-unilever-veteran-india-co-head\n",
            "VCCircle - https://www.vccircle.com/threeinfra-investment-trusts-eye-500-mn-debt-in-coming-weeks\n",
            "VCCircle - https://www.vccircle.com/tilaknagarindustries-to-acquire-imperial-blue-whisky-from-pernod-ricard\n",
            "YourStory - https://yourstory.com/2025/07/funding-infra-tech-enlite-seriesa-round-avaana-capital\n",
            "YourStory - https://yourstory.com/2025/07/netrasemi-rs-107-crore-series-a-funding-zoho-unicorn-india-ventures\n",
            "YourStory - https://yourstory.com/2025/07/superk-raises-rs-100-cr-series-b-round-binny-bansal-mithun-sacheti\n"
          ]
        }
      ],
      "source": [
        "import asyncio\n",
        "import requests\n",
        "from playwright.async_api import async_playwright\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from datetime import datetime\n",
        "\n",
        "class WebsiteURLFetcher:\n",
        "    def __init__(self, target_date: str):\n",
        "        \"\"\"\n",
        "        Initialize the fetcher with a target date in 'YYYY-MM-DD' format.\n",
        "        \"\"\"\n",
        "        self.target_date = datetime.strptime(target_date, \"%Y-%m-%d\")\n",
        "        self.urls = []\n",
        "\n",
        "    def format_date_for_website(self, website: str) -> str:\n",
        "        \"\"\"\n",
        "        Format the target date according to the website's expected date format.\n",
        "        \"\"\"\n",
        "        if website == \"Inc42\":\n",
        "            return self.target_date.strftime(\"%dth %B, %Y\")  # e.g., 23rd July, 2025\n",
        "        elif website == \"Entrackr\":\n",
        "            return self.target_date.strftime(\"%b %d, %Y\")  # e.g., Jul 24, 2025\n",
        "        elif website == \"VCCircle\":\n",
        "            return self.target_date.strftime(\"%d %B, %Y\")  # e.g., 24 July, 2025\n",
        "        elif website == \"EconomicTimes\":\n",
        "            return self.target_date.strftime(\"%d %b, %Y\")  # e.g., 23 Jul, 2025\n",
        "        elif website == \"YourStory\":\n",
        "            return self.target_date.strftime(\"%dth %b %Y\")  # e.g., 24th Jul 2025\n",
        "        else:\n",
        "            return self.target_date.strftime(\"%Y-%m-%d\")  # Default format\n",
        "\n",
        "    async def fetch_inc42_urls(self):\n",
        "        BASE_URL = \"https://inc42.com/buzz/\"\n",
        "        TARGET_DATE = self.format_date_for_website(\"Inc42\")\n",
        "\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(headless=True)\n",
        "            context = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
        "            page = await context.new_page()\n",
        "            await page.goto(BASE_URL, timeout=120_000)\n",
        "            await asyncio.sleep(5)\n",
        "            page_content = await page.content()\n",
        "            await browser.close()\n",
        "\n",
        "        soup = BeautifulSoup(page_content, \"html.parser\")\n",
        "        articles = set()\n",
        "        for div in soup.find_all(['div', 'article']):\n",
        "            if TARGET_DATE in div.get_text():\n",
        "                a = div.find('a', href=True)\n",
        "                if a:\n",
        "                    full_url = urljoin(BASE_URL, a['href'])\n",
        "                    if full_url.startswith(\"https://inc42.com/buzz\"):\n",
        "                        articles.add(f\"Inc 42 - {full_url}\")\n",
        "        self.urls.extend(list(articles))\n",
        "\n",
        "    def fetch_entrackr_urls(self):\n",
        "        BASE_URL = \"https://entrackr.com/\"\n",
        "        TARGET_DATE = self.format_date_for_website(\"Entrackr\")\n",
        "\n",
        "        r = requests.get(BASE_URL)\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        urls = set()\n",
        "\n",
        "        for container in soup.select(\"div.small-post\"):\n",
        "            for date_span in container.find_all(\"span\", class_=\"publish-date\"):\n",
        "                date_text = date_span.text.strip()\n",
        "                if date_text.startswith(TARGET_DATE):\n",
        "                    a = container.find(\"a\", href=True)\n",
        "                    if a:\n",
        "                        urls.add(f\"Entrackr - {urljoin(BASE_URL, a['href'])}\")\n",
        "                    break\n",
        "\n",
        "        for container in soup.select(\"div.gallery_content\"):\n",
        "            for date_span in container.find_all(\"span\", class_=\"publish-date\"):\n",
        "                date_text = date_span.text.strip()\n",
        "                if date_text.startswith(TARGET_DATE):\n",
        "                    a = container.find(\"a\", href=True)\n",
        "                    if a:\n",
        "                        urls.add(f\"Entrackr - {urljoin(BASE_URL, a['href'])}\")\n",
        "                    break\n",
        "        self.urls.extend(list(urls))\n",
        "\n",
        "    async def fetch_vccircle_urls(self):\n",
        "        BASE_URLS = [\n",
        "            \"https://www.vccircle.com/deal-type/venture-capital\",\n",
        "            \"https://www.vccircle.com/deal-type/pe\",\n",
        "            \"https://www.vccircle.com/deal-type/m-a\",\n",
        "            \"https://www.vccircle.com/deal-type/credit\",\n",
        "            \"https://www.vccircle.com/industry/infrastructure\",\n",
        "            \"https://www.vccircle.com/economy/finance\",\n",
        "            \"https://www.vccircle.com/industry/tmt\"\n",
        "        ]\n",
        "        TARGET_DATE = self.format_date_for_website(\"VCCircle\")\n",
        "\n",
        "        articles = set()\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(headless=True)\n",
        "            context = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
        "            page = await context.new_page()\n",
        "            for BASE_URL in BASE_URLS:\n",
        "                await page.goto(BASE_URL, timeout=120_000)\n",
        "                await asyncio.sleep(5)\n",
        "                html = await page.content()\n",
        "                soup = BeautifulSoup(html, \"html.parser\")\n",
        "                for card in soup.find_all(['article', 'div', 'section']):\n",
        "                    text = card.get_text()\n",
        "                    if TARGET_DATE in text:\n",
        "                        a = card.find('a', href=True)\n",
        "                        if a:\n",
        "                            url = urljoin(BASE_URL, a['href'])\n",
        "                            suffix = url.split(\"vccircle.com/\")[-1]\n",
        "                            if len(suffix) >= 15:\n",
        "                                articles.add(f\"VCCircle - {url}\")\n",
        "            await browser.close()\n",
        "        self.urls.extend(list(articles))\n",
        "\n",
        "    def fetch_economic_times_urls(self):\n",
        "        BASE_URL = \"https://economictimes.indiatimes.com/topic/fund-raise\"\n",
        "        TARGET_DATE = self.format_date_for_website(\"EconomicTimes\")\n",
        "\n",
        "        try:\n",
        "            r = requests.get(BASE_URL, timeout=30)  # Added timeout for requests\n",
        "            r.raise_for_status() # Raise an exception for bad status codes\n",
        "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "            articles = set()\n",
        "            for article in soup.find_all(\"div\", recursive=True):\n",
        "                text = article.get_text()\n",
        "                if TARGET_DATE in text:\n",
        "                    a = article.find(\"a\", href=True)\n",
        "                    if a and '/articleshow/' in a['href']:\n",
        "                        articles.add(f\"Economic Times - {urljoin(BASE_URL, a['href'])}\")\n",
        "            self.urls.extend(list(articles))\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching Economic Times URLs: {e}\")\n",
        "\n",
        "\n",
        "    async def fetch_yourstory_urls(self):\n",
        "        BASE_URL = \"https://yourstory.com\"\n",
        "        CATEGORY_URL = \"https://yourstory.com/category/funding\"\n",
        "        TARGET_DATE = self.format_date_for_website(\"YourStory\")\n",
        "\n",
        "        async with async_playwright() as p:\n",
        "            browser = await p.chromium.launch(\n",
        "                headless=True,\n",
        "                args=[\n",
        "                    \"--disable-blink-features=AutomationControlled\",\n",
        "                    \"--no-sandbox\",\n",
        "                    \"--disable-dev-shm-usage\",\n",
        "                    \"--window-size=1920,1080\",\n",
        "                    \"--disable-gpu\",\n",
        "                    \"--no-zygote\"\n",
        "                ]\n",
        "            )\n",
        "            context = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\")\n",
        "            await context.add_init_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
        "            page = await context.new_page()\n",
        "            await page.goto(CATEGORY_URL, timeout=60000)\n",
        "            await page.wait_for_selector(\"body\", timeout=60000)\n",
        "            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
        "            await page.wait_for_timeout(5000)\n",
        "            spans = await page.query_selector_all(\"span.sc-36431a7-0.hmxwID\")\n",
        "            links = set()\n",
        "            for span in spans:\n",
        "                date_text = (await span.inner_text()).strip()\n",
        "                if date_text == TARGET_DATE:\n",
        "                    container = await span.evaluate_handle(\"el => el.closest('div.sc-c9f6afaa-2.ckwFzl')\")\n",
        "                    if container:\n",
        "                        a_tag = await container.query_selector(\"a[href^='/']\")\n",
        "                        if a_tag:\n",
        "                            href = await a_tag.get_attribute(\"href\")\n",
        "                            if href:\n",
        "                                links.add(f\"YourStory - {urljoin(BASE_URL, href)}\")\n",
        "            await browser.close()\n",
        "        self.urls.extend(list(links))\n",
        "\n",
        "    async def fetch_all_urls(self):\n",
        "        \"\"\"\n",
        "        Fetch URLs from all websites for the given date.\n",
        "        \"\"\"\n",
        "        await self.fetch_inc42_urls()\n",
        "        self.fetch_entrackr_urls()\n",
        "        await self.fetch_vccircle_urls()\n",
        "        self.fetch_economic_times_urls() # Changed to synchronous call\n",
        "        await self.fetch_yourstory_urls()\n",
        "        return sorted(self.urls)\n",
        "\n",
        "    async def get_urls(self):\n",
        "        \"\"\"\n",
        "        Run the async fetcher and return the collected URLs.\n",
        "        \"\"\"\n",
        "        return await self.fetch_all_urls()\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    async def main():\n",
        "        fetcher = WebsiteURLFetcher(\"2025-07-24\")\n",
        "        urls = await fetcher.get_urls()\n",
        "        print(\"Collected URLs:\")\n",
        "        for url in urls:\n",
        "            print(url)\n",
        "    import nest_asyncio\n",
        "    nest_asyncio.apply()\n",
        "    await main()"
      ]
    }
  ]
}